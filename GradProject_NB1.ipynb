{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> DS200A Computer Vision Assignment</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>  Part One: Data Preparation </h2>\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>  Import Statements </h3>\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process STDOUT and STDERR is being redirected to /tmp/raylogs/.\n",
      "Waiting for redis server at 127.0.0.1:47834 to respond...\n",
      "Waiting for redis server at 127.0.0.1:41222 to respond...\n",
      "Starting the Plasma object store with 6.00 GB memory.\n",
      "Starting local scheduler with the following resources: {'CPU': 4, 'GPU': 0}.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'local_scheduler_socket_names': ['/tmp/scheduler2761657'],\n",
       " 'node_ip_address': '10.142.159.205',\n",
       " 'object_store_addresses': [ObjectStoreAddress(name='/tmp/plasma_store9863268', manager_name='/tmp/plasma_manager59669040', manager_port=40436)],\n",
       " 'raylet_socket_names': [],\n",
       " 'redis_address': '10.142.159.205:47834',\n",
       " 'webui_url': ''}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import anything you need here\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import skimage\n",
    "from skimage import data\n",
    "from skimage import io\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "import ray\n",
    "ray.init(include_webui=False, num_cpus=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Using the code for reference, take the given folder and create a dataframe with the picture object, and the encoding as listed below. </h4>\t\n",
    "0=Airplanes, 1=Bear, 2=Blimp, 3=Comet, 4=Crab, 5=Dog, 6=Dolphin, 7=Giraffe, 8=Goat, 9=Gorilla, 10=Kangaroo, 11=Killer-Whale, 12=Leopards, 13=Llama, 14= Penguin, 15= Porcupine, 16=Teddy-Bear, 17=Triceratops, 18=Unicorn, 19=Zebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transformed_image_from_path(file_path, outFile_size):\n",
    "    \"\"\"\n",
    "    Read an image from 'file_path', and return its aspect ratio and resized form\n",
    "    \"\"\"\n",
    "    image = io.imread(file_path)\n",
    "    aspect = image.shape[1]/image.shape[0]\n",
    "    \n",
    "    # print(aspect)\n",
    "    transformed_image = skimage.transform.resize(image, outFile_size,\\\n",
    "                                                 preserve_range=True)\n",
    "    return transformed_image, aspect\n",
    "\n",
    "@ray.remote(num_return_vals=2)\n",
    "def get_transformed_image_from_path_remote(file_path, outFile_size):\n",
    "    \"\"\"\n",
    "    Ray parallelization for the function get_transformed_image_from_path()\n",
    "    \"\"\"\n",
    "    return get_transformed_image_from_path(file_path, outFile_size)\n",
    "\n",
    "def getCategoryEncodings():\n",
    "    \"\"\"\n",
    "    Given the classes and their encoding as in above markdown cell\n",
    "    return a dictionary with the corresponding mapping\n",
    "    \"\"\"\n",
    "    category_list = [\"Airplanes\",\"Bear\",\"Blimp\",\"Comet\",\"Crab\",\"Dog\",\"Dolphin\",\n",
    "                     \"Giraffe\",\"Goat\",\"Gorilla\",\"Kangaroo\",\"Killer-Whale\",\n",
    "                     \"Leopards\",\"Llama\",\"Penguin\",\"Porcupine\",\"Teddy-Bear\",\n",
    "                     \"Triceratops\",\"Unicorn\",\"Zebra\"]\n",
    "    category_list = list(map(lambda x: x.lower(), category_list))\n",
    "    category_encodings = dict(zip(category_list, range(len(category_list))))\n",
    "    \n",
    "    # # Uncomment to view category encoding dict\n",
    "    # print(category_encodings)\n",
    "    return category_encodings\n",
    "\n",
    "def read_organize_data(dir_path, outFile_size):\n",
    "    \"\"\"\n",
    "    Given a global directory path and output File dimension as tuple,\n",
    "    return a dataFrame with all the images resized to outFile_size \n",
    "    having corresponding encodings for class labels.\n",
    "    \n",
    "    input:  dir_path = string path of root directory\n",
    "            outFile_size = tuple of final resized image eg. (128, 128)\n",
    "    \n",
    "    returns: DataFrame with columns  \n",
    "                'image' has input image resized to outFile_size\n",
    "                'class' class label/encoding for the class\n",
    "                'aspect' aspect ratio of the images before resizing\n",
    "                'filename' the filename of the input image\n",
    "    \"\"\"\n",
    "    \n",
    "    #Get encodings\n",
    "    category_encodings = getCategoryEncodings()\n",
    "    \n",
    "    image_df = pd.DataFrame(columns = ['image', 'class'])\n",
    "    data, encodings, aspects, filenames = [], [], [], []\n",
    "    \n",
    "    for category in os.listdir(dir_path):  # iterate over directories\n",
    "        if category[0] != '.':  #Protecting against temporary files \n",
    "            for file_name in os.listdir(dir_path + category):\n",
    "                if file_name[0] != '.':\n",
    "                    file_encode = category_encodings[category]\n",
    "                    file_path = dir_path + category + '/' + file_name\n",
    "                    image_data, aspect = get_transformed_image_from_path_remote.remote(file_path, outFile_size) #\n",
    "                    \n",
    "                    # #  Uncomment to view thumbnails for all training images\n",
    "                    # plt.figure()\n",
    "                    # io.imshow(image_data)\n",
    "\n",
    "                    filenames.append(file_name)\n",
    "                    encodings.append(file_encode)\n",
    "                    data.append(image_data)\n",
    "                    aspects.append(aspect)\n",
    "    \n",
    "    image_df['filename'] = filenames    \n",
    "    image_df['class'] = encodings        \n",
    "    image_df['image'] = ray.get(data) \n",
    "    image_df['aspect'] = ray.get(aspects)\n",
    "    \n",
    "    return image_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to compute results: 20.299235820770264 seconds\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"data/20_categories_training/\"\n",
    "resize_to = (128, 128)\n",
    "\n",
    "start_time = time.time()\n",
    "starting_data = read_organize_data(data_dir, resize_to)\n",
    "end_time = time.time()\n",
    "print(\"Time to compute results: {} seconds\".format(end_time - start_time))\n",
    "# starting_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store this dataFrame in a pickle compressed form to read and process\n",
    "# in future notebooks\n",
    "starting_data.to_pickle(\"./starting_data_part1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>aspect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[55.09130859374934, 55.08886718749936, 63.08...</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[9.960937500000142, 14.941406250000213, 18.9...</td>\n",
       "      <td>1.897638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[250.016326904297, 249.016326904297, 254.632...</td>\n",
       "      <td>0.853868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[95.7189331054702, 74.06268310546987, 76.031...</td>\n",
       "      <td>1.524194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[24.203125, 51.203125, 61.82855224609375], [...</td>\n",
       "      <td>0.665714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               image    aspect\n",
       "0  [[[55.09130859374934, 55.08886718749936, 63.08...  0.666667\n",
       "1  [[[9.960937500000142, 14.941406250000213, 18.9...  1.897638\n",
       "2  [[[250.016326904297, 249.016326904297, 254.632...  0.853868\n",
       "3  [[[95.7189331054702, 74.06268310546987, 76.031...  1.524194\n",
       "4  [[[24.203125, 51.203125, 61.82855224609375], [...  0.665714"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "val_data_dir = \"data/20_Validation/\"\n",
    "resize_to = (128, 128)\n",
    "\n",
    "val_image_df = pd.DataFrame(columns = ['image'])\n",
    "data, fileNumber, aspects, filenames = [], [], [], []\n",
    "reg = r\"(\\d)+\"\n",
    "\n",
    "for file_name in os.listdir(val_data_dir):\n",
    "    if file_name[0] != '.':\n",
    "#         file_encode = category_encodings[category]\n",
    "        file_path = val_data_dir +  file_name\n",
    "        \n",
    "\n",
    "        num = int(re.search(reg, file_name)[0])\n",
    "        \n",
    "        image_data, aspect = get_transformed_image_from_path_remote.remote(file_path, resize_to) # \n",
    "\n",
    "        # #  Uncomment to view thumbnails for all training images\n",
    "        # plt.figure()\n",
    "        # io.imshow(image_data)\n",
    "\n",
    "        filenames.append(file_name)\n",
    "        fileNumber.append(num)\n",
    "        data.append(image_data)\n",
    "        aspects.append(aspect)\n",
    "    \n",
    "val_image_df[\"filenumber\"] = fileNumber\n",
    "val_image_df['filename'] = filenames    \n",
    "val_image_df['image'] = ray.get(data) \n",
    "val_image_df['aspect'] = ray.get(aspects)\n",
    "\n",
    "test_df = val_image_df.sort_values(by=\"filenumber\").reset_index() \\\n",
    "            .drop(columns=[\"index\", \"filename\", \"filenumber\"])\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_pickle(\"./testing_data_part1.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
