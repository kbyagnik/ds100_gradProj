{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> DS200A Computer Vision Assignment</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>  Part Two: Feature Selection </h2>\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> In this section, we would like you to select between 15 and 20 features to focus your model on. This will require significant explatoratory research. The first one is already implemented for you, and the next two are pre-specified.  </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "\n",
    "starting_data = pd.read_pickle(\"./starting_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [[[0.7190472509346757, 0.6931705186180039, 0.5...\n",
       "1    [[[0.8265946633675518, 0.7424424619359127, 0.6...\n",
       "2    [[[0.6663370332151065, 0.5787376925531846, 0.4...\n",
       "3    [[[0.5976653606137808, 0.5211597906316028, 0.3...\n",
       "4    [[[0.5769127960882934, 0.5890974229457331, 0.3...\n",
       "Name: features, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def get_intensity_based_features(image):\n",
    "    avg_channel = np.zeros(3)\n",
    "    for i in range(3):\n",
    "        avg_channel[i] = np.mean(image[:,:,i] )\n",
    "    a=np.argmax(image, axis=2)\n",
    "    ind, counts = np.unique(a, return_counts=True)\n",
    "    percent_max = counts/np.sum(counts)\n",
    "    return [avg_channel, percent_max]\n",
    "\n",
    "def getImageFeatures(image):\n",
    "    # handle condition when images are black-white\n",
    "    # by copying b/w image to all three channels\n",
    "    \n",
    "    if len(image.shape) == 2:\n",
    "        temp = np.zeros((image.shape[0], image.shape[1], 3))\n",
    "        for i in range(3):\n",
    "            temp[:,:,i] = image\n",
    "        image = temp\n",
    "    \n",
    "    m,n,k = image.shape\n",
    "    \n",
    "    # Get full image features\n",
    "    full_image_features= get_intensity_based_features(image)\n",
    "    \n",
    "    patch_min = int(m/4)\n",
    "    patch_max = int(3*m/4)\n",
    "    cropped = image[patch_min:patch_max, patch_min:patch_max, :]\n",
    "    \n",
    "    # Get central cropped image features\n",
    "    cropped_image_features = get_intensity_based_features(cropped)\n",
    "    \n",
    "    \n",
    "    return [full_image_features, cropped_image_features] \n",
    "\n",
    "starting_data[\"features\"] = starting_data[\"image\"].apply(getImageFeatures)\n",
    "starting_data[\"features\"].head()\n",
    "\n",
    "# # Returns the pixel size of the image\n",
    "# def ft1(image):\n",
    "#     raise notImplementedError()\n",
    "# # Returns the average of the red-channel pictures for the images\n",
    "# def ft2(image):\n",
    "#     raise notImplementedError()\n",
    "# #Returns the aspect ratio of the image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define more features above, performing any EDA research below. We expect all external sources sited, and a couple significant different graphs indicating some form of EDA. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Graphs </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store -r starting_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Sources </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['blimp_0022.jpg', 'comet_0006.jpg', 'comet_0011.jpg', 'comet_0013.jpg', 'comet_0021.jpg', 'comet_0036.jpg', 'comet_0038.jpg', 'comet_0041.jpg', 'comet_0049.jpg', 'comet_0052.jpg', 'comet_0053.jpg', 'comet_0057.jpg', 'comet_0058.jpg', 'crab_0045.jpg', 'dolphin_0025.jpg', 'gorilla_0128.jpg']\n"
     ]
    }
   ],
   "source": [
    "files=[]\n",
    "for i,image in enumerate(starting_data[\"image\"]):\n",
    "    if len(image.shape) < 3:\n",
    "        files.append(starting_data.iloc[i, 2])\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> DataFrame Creation </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_frame(df):\n",
    "    return df\n",
    "    #Returns data-frame with all the features now inside, and calculated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_frame(data_from_nb1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
