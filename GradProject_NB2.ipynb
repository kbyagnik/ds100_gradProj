{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> DS200A Computer Vision Assignment</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>  Part Two: Feature Selection </h2>\t\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> In this section, we would like you to select between 15 and 20 features to focus your model on. This will require significant explatoratory research. The first one is already implemented for you, and the next two are pre-specified.  </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-cdf4b1989d08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mstarting_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./starting_data.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import cv2 as cv\n",
    "starting_data = pd.read_pickle(\"./starting_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>aspect</th>\n",
       "      <th>argmax_r</th>\n",
       "      <th>argmax_g</th>\n",
       "      <th>argmax_b</th>\n",
       "      <th>red</th>\n",
       "      <th>green</th>\n",
       "      <th>blue</th>\n",
       "      <th>contrast</th>\n",
       "      <th>red_crop</th>\n",
       "      <th>green_crop</th>\n",
       "      <th>blue_crop</th>\n",
       "      <th>argmax__crop_r</th>\n",
       "      <th>argmax_crop_g</th>\n",
       "      <th>argmax_crop_b</th>\n",
       "      <th>contrast_crop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.426829</td>\n",
       "      <td>0.572327</td>\n",
       "      <td>0.421021</td>\n",
       "      <td>0.006653</td>\n",
       "      <td>0.719047</td>\n",
       "      <td>0.693171</td>\n",
       "      <td>0.585263</td>\n",
       "      <td>0.997897</td>\n",
       "      <td>0.631888</td>\n",
       "      <td>0.629310</td>\n",
       "      <td>0.537280</td>\n",
       "      <td>0.536377</td>\n",
       "      <td>0.460449</td>\n",
       "      <td>0.003174</td>\n",
       "      <td>0.982738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2.179348</td>\n",
       "      <td>0.971802</td>\n",
       "      <td>0.028198</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.826595</td>\n",
       "      <td>0.742442</td>\n",
       "      <td>0.646464</td>\n",
       "      <td>0.979614</td>\n",
       "      <td>0.675802</td>\n",
       "      <td>0.498426</td>\n",
       "      <td>0.410969</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.940746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2.381818</td>\n",
       "      <td>0.705322</td>\n",
       "      <td>0.056702</td>\n",
       "      <td>0.237976</td>\n",
       "      <td>0.666337</td>\n",
       "      <td>0.578738</td>\n",
       "      <td>0.437090</td>\n",
       "      <td>0.993714</td>\n",
       "      <td>0.611749</td>\n",
       "      <td>0.418503</td>\n",
       "      <td>0.193338</td>\n",
       "      <td>0.809326</td>\n",
       "      <td>0.065430</td>\n",
       "      <td>0.125244</td>\n",
       "      <td>0.864494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2.311765</td>\n",
       "      <td>0.835449</td>\n",
       "      <td>0.161743</td>\n",
       "      <td>0.002808</td>\n",
       "      <td>0.597665</td>\n",
       "      <td>0.521160</td>\n",
       "      <td>0.306170</td>\n",
       "      <td>0.994251</td>\n",
       "      <td>0.575981</td>\n",
       "      <td>0.407758</td>\n",
       "      <td>0.148851</td>\n",
       "      <td>0.943848</td>\n",
       "      <td>0.052734</td>\n",
       "      <td>0.003418</td>\n",
       "      <td>0.969045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2.244318</td>\n",
       "      <td>0.404968</td>\n",
       "      <td>0.515442</td>\n",
       "      <td>0.079590</td>\n",
       "      <td>0.576913</td>\n",
       "      <td>0.589097</td>\n",
       "      <td>0.337259</td>\n",
       "      <td>0.998115</td>\n",
       "      <td>0.393732</td>\n",
       "      <td>0.401980</td>\n",
       "      <td>0.183056</td>\n",
       "      <td>0.262695</td>\n",
       "      <td>0.493408</td>\n",
       "      <td>0.243896</td>\n",
       "      <td>0.994631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class    aspect  argmax_r  argmax_g  argmax_b       red     green  \\\n",
       "0      0  2.426829  0.572327  0.421021  0.006653  0.719047  0.693171   \n",
       "1      0  2.179348  0.971802  0.028198  0.000000  0.826595  0.742442   \n",
       "2      0  2.381818  0.705322  0.056702  0.237976  0.666337  0.578738   \n",
       "3      0  2.311765  0.835449  0.161743  0.002808  0.597665  0.521160   \n",
       "4      0  2.244318  0.404968  0.515442  0.079590  0.576913  0.589097   \n",
       "\n",
       "       blue  contrast  red_crop  green_crop  blue_crop  argmax__crop_r  \\\n",
       "0  0.585263  0.997897  0.631888    0.629310   0.537280        0.536377   \n",
       "1  0.646464  0.979614  0.675802    0.498426   0.410969        0.984375   \n",
       "2  0.437090  0.993714  0.611749    0.418503   0.193338        0.809326   \n",
       "3  0.306170  0.994251  0.575981    0.407758   0.148851        0.943848   \n",
       "4  0.337259  0.998115  0.393732    0.401980   0.183056        0.262695   \n",
       "\n",
       "   argmax_crop_g  argmax_crop_b  contrast_crop  \n",
       "0       0.460449       0.003174       0.982738  \n",
       "1       0.015625       0.000000       0.940746  \n",
       "2       0.065430       0.125244       0.864494  \n",
       "3       0.052734       0.003418       0.969045  \n",
       "4       0.493408       0.243896       0.994631  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def get_intensity_based_features(image):\n",
    "#     avg_channel = np.zeros(3)\n",
    "#     for i in range(3):\n",
    "#         avg_channel[i] = np.mean(image[:,:,i] )\n",
    "#     a=np.argmax(image, axis=2)\n",
    "#     ind, counts = np.unique(a, return_counts=True)\n",
    "#     percent_max = counts/np.sum(counts)\n",
    "#     return [avg_channel, percent_max]\n",
    "\n",
    "# def getImageFeatures(image):\n",
    "#     # handle condition when images are black-white\n",
    "#     # by copying b/w image to all three channels\n",
    "    \n",
    "#     if len(image.shape) == 2:\n",
    "#         temp = np.zeros((image.shape[0], image.shape[1], 3))\n",
    "#         for i in range(3):\n",
    "#             temp[:,:,i] = image\n",
    "#         image = temp\n",
    "    \n",
    "#     m,n,k = image.shape\n",
    "    \n",
    "#     # Get full image features\n",
    "#     full_image_features= get_intensity_based_features(image)\n",
    "    \n",
    "#     patch_min = int(m/4)\n",
    "#     patch_max = int(3*m/4)\n",
    "#     cropped = image[patch_min:patch_max, patch_min:patch_max, :]\n",
    "    \n",
    "#     # Get central cropped image features\n",
    "#     cropped_image_features = get_intensity_based_features(cropped)\n",
    "    \n",
    "    \n",
    "#     return [full_image_features, cropped_image_features] \n",
    "\n",
    "def normalize(image):\n",
    "    if len(image.shape) == 2:\n",
    "        temp = np.zeros((image.shape[0], image.shape[1], 3))\n",
    "        for i in range(3):\n",
    "            temp[:,:,i] = image\n",
    "        image = temp\n",
    "    return image\n",
    "\n",
    "# Returns the average of the red-channel pictures for the images\n",
    "def red_avg(image):\n",
    "    return np.mean(image[:, :, 0])\n",
    "\n",
    "# Returns the average of the green-channel pictures for the images\n",
    "def green_avg(image):\n",
    "    return np.mean(image[:, :, 1])\n",
    "\n",
    "# Returns the average of the blue-channel pictures for the images\n",
    "def blue_avg(image):\n",
    "    return np.mean(image[:, :, 2])\n",
    "\n",
    "def argmax(image):\n",
    "    orig = np.zeros(3)\n",
    "    a = np.argmax(image, axis = 2)\n",
    "    vals, counts = np.unique(a, return_counts=True)\n",
    "    for i in range(3):\n",
    "        if i in vals:\n",
    "            orig[i] = counts[np.where(vals == i)]\n",
    "    percent_max = orig/np.sum(orig)\n",
    "    if len(percent_max) != 3:\n",
    "        print('Help! Percent max length is not 3')        \n",
    "    return percent_max\n",
    "\n",
    "def crop(image):\n",
    "    m, n, k = image.shape\n",
    "    patch_min = int(m/4)\n",
    "    patch_max = int(3*m/4)\n",
    "    cropped = image[patch_min:patch_max, patch_min:patch_max, :]    \n",
    "    return cropped\n",
    "\n",
    "def contrast(image):\n",
    "    vals = np.zeros(3)\n",
    "    for i in range(3):\n",
    "        vals[i] = (np.max(image[:, :, i]) - np.min(image[:, :, i]))\n",
    "    return np.mean(vals)\n",
    "\n",
    "def getImageFeatures(df):\n",
    "    df[\"image\"] = df[\"image\"].apply(normalize)\n",
    "    df[\"red\"] = df[\"image\"].apply(red_avg)\n",
    "    df[\"green\"] = df[\"image\"].apply(green_avg)\n",
    "    df[\"blue\"] = df[\"image\"].apply(blue_avg)\n",
    "    df[\"argmax\"] = df[\"image\"].apply(argmax)\n",
    "    df[[\"argmax_r\",\"argmax_g\",\"argmax_b\"]] = pd.DataFrame(df.argmax.values.tolist(), index= df.index)\n",
    "    df[\"contrast\"] = df[\"image\"].apply(contrast)\n",
    "    \n",
    "    df[\"cropped\"] = df[\"image\"].apply(crop)\n",
    "    df[\"red_crop\"] = df[\"cropped\"].apply(red_avg)\n",
    "    df[\"green_crop\"] = df[\"cropped\"].apply(green_avg)\n",
    "    df[\"blue_crop\"] = df[\"cropped\"].apply(blue_avg)\n",
    "    df[\"argmax_crop\"] = df[\"cropped\"].apply(argmax)\n",
    "    df[[\"argmax__crop_r\",\"argmax_crop_g\",\"argmax_crop_b\"]] = pd.DataFrame(df.argmax_crop.values.tolist(), index= df.index)\n",
    "    df[\"contrast_crop\"] = df[\"cropped\"].apply(contrast)\n",
    "\n",
    "    #Uncomment the following line when ready to make the final dataframe for Part 3!\n",
    "    df = df.drop(labels = ['image', 'filename', 'cropped','argmax', 'argmax_crop'], axis = 1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "starting_data = getImageFeatures(starting_data)\n",
    "starting_data.head()\n",
    "#starting_data['argmax'].str.split(',', expand = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edges(image):\n",
    "    image = io.imread(image)\n",
    "    \n",
    "    m,n,k = image.shape\n",
    "    \n",
    "edges_bear = edges(r\"data/20_categories_training/bear/bear_0011.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1501, 16)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starting_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define more features above, performing any EDA research below. We expect all external sources sited, and a couple significant different graphs indicating some form of EDA. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Graphs </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store -r starting_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Sources </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['blimp_0022.jpg', 'comet_0006.jpg', 'comet_0011.jpg', 'comet_0013.jpg', 'comet_0021.jpg', 'comet_0036.jpg', 'comet_0038.jpg', 'comet_0041.jpg', 'comet_0049.jpg', 'comet_0052.jpg', 'comet_0053.jpg', 'comet_0057.jpg', 'comet_0058.jpg', 'crab_0045.jpg', 'dolphin_0025.jpg', 'gorilla_0128.jpg']\n"
     ]
    }
   ],
   "source": [
    "files=[]\n",
    "for i,image in enumerate(starting_data[\"image\"]):\n",
    "    if len(image.shape) < 3:\n",
    "        files.append(starting_data.iloc[i, 2])\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> DataFrame Creation </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_frame(df):\n",
    "    return df\n",
    "    #Returns data-frame with all the features now inside, and calculated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_frame(data_from_nb1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
