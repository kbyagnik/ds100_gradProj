{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1> DS200A Computer Vision Assignment</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>  Part Three: Training Models </h2>\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process STDOUT and STDERR is being redirected to /tmp/raylogs/.\n",
      "Waiting for redis server at 127.0.0.1:39807 to respond...\n",
      "Waiting for redis server at 127.0.0.1:52179 to respond...\n",
      "Starting the Plasma object store with 6.00 GB memory.\n",
      "Starting local scheduler with the following resources: {'CPU': 4, 'GPU': 0}.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'local_scheduler_socket_names': ['/tmp/scheduler15368597'],\n",
       " 'node_ip_address': '10.142.156.36',\n",
       " 'object_store_addresses': [ObjectStoreAddress(name='/tmp/plasma_store81168882', manager_name='/tmp/plasma_manager92512614', manager_port=64178)],\n",
       " 'raylet_socket_names': [],\n",
       " 'redis_address': '10.142.156.36:39807',\n",
       " 'webui_url': ''}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ray\n",
    "ray.init(include_webui=False, num_cpus=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df, label='class'):\n",
    "    \"\"\"\n",
    "    Given input df, splits the data into a training and test sets with given labels\n",
    "    returns X_train, X_valid, Y_train, Y_valid \n",
    "    \"\"\"\n",
    "    train, valid = train_test_split(df, test_size=0.2, random_state=42, shuffle=True, stratify=df[label])\n",
    "    X_train, Y_train = train.drop(columns=label, axis=1, inplace=False), train[label]\n",
    "    X_valid, Y_valid = valid.drop(columns=label, axis=1, inplace=False), valid[label]\n",
    "    return X_train, X_valid, Y_train, Y_valid\n",
    "\n",
    "def accuracy(actual, pred):\n",
    "    \"\"\"\n",
    "    Calculate the accuracy percentage of the predicted values\n",
    "    \"\"\"\n",
    "    return accuracy_score(actual, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Train models using all of the following methods below. Be sure to drop the actual image column, and the encoding\tTake note of the differences in accuracy, and methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_original = pd.read_pickle(\"./train_df.pkl\")\n",
    "train_df = train_df_original.drop(columns=\"filename\", axis=1, inplace=False)\n",
    "X_train, X_valid, Y_train, Y_valid = split(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_logistic_regression(X_train, Y_train, X_valid, Y_valid, solver='liblinear'):\n",
    "    \"\"\"\n",
    "    Given training and validation data, return the classification accuracy of a logistic regression \n",
    "    model. Defaults use l2 penalty and 'liblinear' solver.\n",
    "    \"\"\"\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    clf = LogisticRegression(solver = solver,).fit(X_train, Y_train)\n",
    "    predictions = clf.predict(X_valid)\n",
    "    return accuracy_score(predictions, Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38870431893687707"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_logistic_regression(X_train, Y_train, X_valid, Y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_knn(X_train, Y_train, X_val, Y_val, nearest_neighbor=10):\n",
    "    \"\"\"\n",
    "    Given training and validation data, return the classification accuracy of a K-Nearest-Neighbours \n",
    "    model. Defaults use 10 neighbours.\n",
    "    \"\"\"\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    clf = KNeighborsClassifier(n_neighbors = nearest_neighbor).fit(X_train, Y_train)\n",
    "    predictions = clf.predict(X_valid)\n",
    "    return accuracy(predictions, Y_valid)\n",
    "\n",
    "# using parallelization to speed up the training\n",
    "@ray.remote\n",
    "def train_test_knn_remote(X_train, Y_train, X_val, Y_val, nearest_neighbors=10):\n",
    "    return train_test_knn(X_train, Y_train, X_val, Y_val, nearest_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([20.        ,  0.32890365]),\n",
       " array([10.       ,  0.3255814]),\n",
       " array([21.        ,  0.32225914]),\n",
       " array([16.        ,  0.31893688]),\n",
       " array([14.        ,  0.31893688])]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "param_list = []\n",
    "optimal = []\n",
    "for nearest_neighbor in range(25,0,-1):   # tuning num of nearest neghbour classifiers \n",
    "    acc = train_test_knn_remote.remote(X_train, Y_train, X_valid, Y_valid, nearest_neighbor)\n",
    "    param_list.append(nearest_neighbor)\n",
    "    optimal.append(acc)\n",
    "\n",
    "optimal = ray.get(optimal)\n",
    "optimal = np.column_stack((param_list, optimal))\n",
    "\n",
    "# Display top 5 results along with params sorted on accuracy\n",
    "display(sorted(optimal, key=lambda x:x[1], reverse=True)[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_random_forest(X_train, Y_train, X_valid, Y_valid, num_classifiers=100, depth=5):\n",
    "    \"\"\"\n",
    "    Given training and validation data, return the classification accuracy of a random forest \n",
    "    model. Defaults use num_classifiers=100 and depth=5.\n",
    "    \"\"\"\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    clf = RandomForestClassifier(n_estimators=num_classifiers, max_depth=depth).fit(X_train, Y_train)\n",
    "    predictions = clf.predict(X_valid)\n",
    "    return accuracy_score(Y_valid, predictions)\n",
    "\n",
    "# using parallelization to speed up the training\n",
    "@ray.remote\n",
    "def train_test_random_forest_remote(X_train, Y_train, X_valid, Y_valid, num_classifiers=100, depth=5):\n",
    "    return train_test_random_forest(X_train, Y_train, X_valid, Y_valid, num_classifiers, depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([60.        , 10.        ,  0.41196013]),\n",
       " array([290.        ,  10.        ,   0.40199336]),\n",
       " array([200.        ,  10.        ,   0.40199336]),\n",
       " array([140.        ,   9.        ,   0.40199336]),\n",
       " array([4.40000000e+02, 9.00000000e+00, 3.98671096e-01])]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_list = []\n",
    "d_list = []\n",
    "optimal = []\n",
    "for n in range(500, 49, -10):   # tuning the number of classifiers\n",
    "    for d in range(3, 11):      # tuning the depth of each classifier\n",
    "        acc = train_test_random_forest_remote.remote(X_train, Y_train, X_valid, Y_valid, n, d)\n",
    "        optimal.append(acc)\n",
    "        n_list.append(n)\n",
    "        d_list.append(d)\n",
    "        \n",
    "optimal = ray.get(optimal)\n",
    "optimal = np.column_stack((n_list, d_list, optimal))\n",
    "\n",
    "# Display top 5 results along with params sorted on accuracy\n",
    "display(sorted(optimal, key=lambda x:x[2], reverse=True)[:5])  ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_svm(X_train, Y_train, X_valid, Y_valid, C=10):\n",
    "    \"\"\"\n",
    "    Given training and validation data, return the classification accuracy of a support vector \n",
    "    machine model. Defaults use penalty param C=10 for training.\n",
    "    \"\"\"\n",
    "    from sklearn.svm import LinearSVC\n",
    "    clf = LinearSVC(C = 10).fit(X_train, Y_train)\n",
    "    predictions = clf.predict(X_valid)\n",
    "    return accuracy_score(Y_valid, predictions)\n",
    "\n",
    "# using parallelization to speed up the training\n",
    "@ray.remote\n",
    "def train_test_svm_remote(X_train, Y_train, X_valid, Y_valid, C=10):\n",
    "    return train_test_svm(X_train, Y_train, X_valid, Y_valid, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([7.        , 0.26910299]),\n",
       " array([9.        , 0.21262458]),\n",
       " array([10.        ,  0.18272425]),\n",
       " array([8.        , 0.11960133]),\n",
       " array([6.        , 0.11295681])]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "param_list = []\n",
    "optimal = []\n",
    "\n",
    "for c in range(5,11):    # tuning penalty param c\n",
    "    acc=train_test_svm_remote.remote(X_train, Y_train, X_valid, Y_valid, C=c)\n",
    "    optimal.append(acc)\n",
    "    param_list.append(c)\n",
    "    \n",
    "optimal = ray.get(optimal)\n",
    "optimal = np.column_stack((param_list, optimal))\n",
    "\n",
    "# Display top 5 results along with params sorted on accuracy\n",
    "display(sorted(optimal, key=lambda x:x[1], reverse=True)[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
