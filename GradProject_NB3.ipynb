{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h1> DS200A Computer Vision Assignment</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>  Part Three: Training Models </h2>\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process STDOUT and STDERR is being redirected to /tmp/raylogs/.\n",
      "Waiting for redis server at 127.0.0.1:30559 to respond...\n",
      "Waiting for redis server at 127.0.0.1:47074 to respond...\n",
      "Starting the Plasma object store with 6.00 GB memory.\n",
      "Starting local scheduler with the following resources: {'CPU': 4, 'GPU': 0}.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'local_scheduler_socket_names': ['/tmp/scheduler45599320'],\n",
       " 'node_ip_address': '10.0.0.56',\n",
       " 'object_store_addresses': [ObjectStoreAddress(name='/tmp/plasma_store96378634', manager_name='/tmp/plasma_manager30068380', manager_port=41087)],\n",
       " 'raylet_socket_names': [],\n",
       " 'redis_address': '10.0.0.56:30559',\n",
       " 'webui_url': ''}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ray\n",
    "ray.init(include_webui=False, num_cpus=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df, label='class'):\n",
    "    \"\"\"\n",
    "    Given input df, splits the data into a training and test sets with given labels\n",
    "    returns X_train, X_test, Y_train, Y_test \n",
    "    \"\"\"\n",
    "    train, test = train_test_split(df, test_size=0.2, random_state=42, shuffle=True, stratify=df[label])\n",
    "    X_train, Y_train = train.drop(columns=label, axis=1, inplace=False), train[label]\n",
    "    X_test, Y_test = test.drop(columns=label, axis=1, inplace=False), test[label]\n",
    "    return X_train, X_test, Y_train, Y_test\n",
    "\n",
    "def accuracy(actual, pred):\n",
    "    \"\"\"\n",
    "    Calculate the accuracy percentage of the predicted values\n",
    "    \"\"\"\n",
    "    return accuracy_score(actual, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Train models using all of the following methods below. Be sure to drop the actual image column, and the encoding\tTake note of the differences in accuracy, and methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_original = pd.read_pickle(\"./train_df.pkl\")\n",
    "train_df = train_df_original.drop(columns=\"filename\", axis=1, inplace=False)\n",
    "X_train, X_test, Y_train, Y_test = split(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_logistic_regression(X_train, Y_train, X_valid, Y_valid, solver='liblinear'):\n",
    "    \"\"\"\n",
    "    Given training and validation data, return the classification accuracy of a logistic regression \n",
    "    model. Defaults use l2 penalty and 'liblinear' solver.\n",
    "    \"\"\"\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    clf = LogisticRegression(solver = solver,).fit(X_train, Y_train)\n",
    "    predictions = clf.predict(X_valid)\n",
    "    return accuracy_score(predictions, Y_valid)\n",
    "\n",
    "# train_test_logistic_regression(X_train, Y_train, X_valid, Y_valid)\n",
    "\n",
    "def train_test_logistic_regression_cv(X_train, Y_train, solver='liblinear', C=1.0, k=5):\n",
    "    \"\"\"\n",
    "    Given training data, perform stratified k-fold cross-validation and return the validation scores\n",
    "    \"\"\"\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.model_selection import cross_validate\n",
    "    \n",
    "    logistic = LogisticRegression(solver = solver, C=C)\n",
    "    cv_results = cross_validate(logistic, X=X_train, y=Y_train, cv=k, return_train_score=False, return_estimator=True)\n",
    "    \n",
    "    max_ind = np.where(cv_results[\"test_score\"] == max(cv_results[\"test_score\"]))\n",
    "    max_estimator = cv_results[\"estimator\"][max_ind[0][0]]\n",
    "    return np.mean(cv_results[\"test_score\"]), np.std(cv_results[\"test_score\"]), max_estimator\n",
    "\n",
    "@ray.remote(num_return_vals=3)\n",
    "def train_test_logistic_regression_cv_remote(X_train, Y_train, solver='liblinear', C=1.0, k=5):\n",
    "    return train_test_logistic_regression_cv(X_train, Y_train, solver, C, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean_Val_Acc</th>\n",
       "      <th>Std_Val_Acc</th>\n",
       "      <th>Regularization_Penalty</th>\n",
       "      <th>Num_Folds</th>\n",
       "      <th>Best_Estimator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.410127</td>\n",
       "      <td>0.022898</td>\n",
       "      <td>50.0</td>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression(C=50.0, class_weight=None, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.402614</td>\n",
       "      <td>0.026245</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression(C=10.0, class_weight=None, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.400625</td>\n",
       "      <td>0.032264</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10</td>\n",
       "      <td>LogisticRegression(C=10.0, class_weight=None, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.394885</td>\n",
       "      <td>0.036816</td>\n",
       "      <td>50.0</td>\n",
       "      <td>10</td>\n",
       "      <td>LogisticRegression(C=50.0, class_weight=None, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.392560</td>\n",
       "      <td>0.011722</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression(C=50.0, class_weight=None, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Mean_Val_Acc  Std_Val_Acc  Regularization_Penalty  Num_Folds  \\\n",
       "0      0.410127     0.022898                    50.0          5   \n",
       "1      0.402614     0.026245                    10.0          5   \n",
       "2      0.400625     0.032264                    10.0         10   \n",
       "3      0.394885     0.036816                    50.0         10   \n",
       "4      0.392560     0.011722                    50.0          3   \n",
       "\n",
       "                                      Best_Estimator  \n",
       "0  LogisticRegression(C=50.0, class_weight=None, ...  \n",
       "1  LogisticRegression(C=10.0, class_weight=None, ...  \n",
       "2  LogisticRegression(C=10.0, class_weight=None, ...  \n",
       "3  LogisticRegression(C=50.0, class_weight=None, ...  \n",
       "4  LogisticRegression(C=50.0, class_weight=None, ...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means_list = []\n",
    "std_list = []\n",
    "estimator_list = []\n",
    "penalty_list = []\n",
    "folds_list = []\n",
    "\n",
    "for penalty in [0.5, 1.0, 2.0, 10.0, 50.0]: # \n",
    "    for k in [3, 5, 10]: # \n",
    "        mean_acc, std_acc, estimator = train_test_logistic_regression_cv_remote.remote(X_train, Y_train, solver='liblinear', C=penalty, k=k)\n",
    "        means_list.append(mean_acc)\n",
    "        std_list.append(std_acc)\n",
    "        estimator_list.append(estimator)\n",
    "        penalty_list.append(penalty)\n",
    "        folds_list.append(k)\n",
    "        \n",
    "mean_list = ray.get(means_list)\n",
    "std_list = ray.get(std_list)\n",
    "estimator_list = ray.get(estimator_list)\n",
    "\n",
    "optimal = np.column_stack((mean_list, std_list, penalty_list, folds_list, estimator_list))\n",
    "optimal = pd.DataFrame(sorted(optimal, key=lambda x:x[0], reverse=True), columns=[\"Mean_Val_Acc\", \"Std_Val_Acc\", \"Regularization_Penalty\", \"Num_Folds\", \"Best_Estimator\"])\n",
    "\n",
    "# Display top 5 results along with params sorted on accuracy\n",
    "optimal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4053156146179402"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = optimal.loc[0,\"Best_Estimator\"].predict(X_test)\n",
    "accuracy(Y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_knn(X_train, Y_train, X_val, Y_val, nearest_neighbor=10):\n",
    "    \"\"\"\n",
    "    Given training and validation data, return the classification accuracy of a K-Nearest-Neighbours \n",
    "    model. Defaults use 10 neighbours.\n",
    "    \"\"\"\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    clf = KNeighborsClassifier(n_neighbors = nearest_neighbor).fit(X_train, Y_train)\n",
    "    predictions = clf.predict(X_valid)\n",
    "    return accuracy(predictions, Y_valid)\n",
    "\n",
    "# using parallelization to speed up the training\n",
    "@ray.remote\n",
    "def train_test_knn_remote(X_train, Y_train, X_val, Y_val, nearest_neighbors=10):\n",
    "    return train_test_knn(X_train, Y_train, X_val, Y_val, nearest_neighbors)\n",
    "\n",
    "def train_test_knn_cv(X_train, Y_train, nearest_neighbor=10, k=5):\n",
    "    from sklearn.model_selection import cross_validate\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    knn = KNeighborsClassifier(n_neighbors = nearest_neighbor)\n",
    "    \n",
    "    cv_results = cross_validate(knn, X=X_train, y=Y_train, cv=k, return_train_score=False, return_estimator=True)\n",
    "    \n",
    "    max_ind = np.where(cv_results[\"test_score\"] == max(cv_results[\"test_score\"]))\n",
    "    max_estimator = cv_results[\"estimator\"][max_ind[0][0]]\n",
    "    return np.mean(cv_results[\"test_score\"]), np.std(cv_results[\"test_score\"]), max_estimator\n",
    "\n",
    "\n",
    "@ray.remote(num_return_vals=3)\n",
    "def train_test_knn_cv_remote(X_train, Y_train, nearest_neighbor=10, k=5):\n",
    "    return train_test_knn_cv(X_train, Y_train, nearest_neighbor, k)\n",
    "\n",
    "# train_test_knn_cv(X_train, Y_train, nearest_neighbor=10, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean_Val_Acc</th>\n",
       "      <th>Std_Val_Acc</th>\n",
       "      <th>Num_nearest_neighbor</th>\n",
       "      <th>Num_Folds</th>\n",
       "      <th>Best_Estimator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.298723</td>\n",
       "      <td>0.040594</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "      <td>KNeighborsClassifier(algorithm='auto', leaf_si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.292592</td>\n",
       "      <td>0.040900</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>KNeighborsClassifier(algorithm='auto', leaf_si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.291523</td>\n",
       "      <td>0.012055</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>KNeighborsClassifier(algorithm='auto', leaf_si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.287679</td>\n",
       "      <td>0.037791</td>\n",
       "      <td>22</td>\n",
       "      <td>10</td>\n",
       "      <td>KNeighborsClassifier(algorithm='auto', leaf_si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.287579</td>\n",
       "      <td>0.053569</td>\n",
       "      <td>22</td>\n",
       "      <td>15</td>\n",
       "      <td>KNeighborsClassifier(algorithm='auto', leaf_si...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Mean_Val_Acc  Std_Val_Acc  Num_nearest_neighbor  Num_Folds  \\\n",
       "0      0.298723     0.040594                    18         10   \n",
       "1      0.292592     0.040900                    16         10   \n",
       "2      0.291523     0.012055                    18          3   \n",
       "3      0.287679     0.037791                    22         10   \n",
       "4      0.287579     0.053569                    22         15   \n",
       "\n",
       "                                      Best_Estimator  \n",
       "0  KNeighborsClassifier(algorithm='auto', leaf_si...  \n",
       "1  KNeighborsClassifier(algorithm='auto', leaf_si...  \n",
       "2  KNeighborsClassifier(algorithm='auto', leaf_si...  \n",
       "3  KNeighborsClassifier(algorithm='auto', leaf_si...  \n",
       "4  KNeighborsClassifier(algorithm='auto', leaf_si...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_list = []\n",
    "means_list = []\n",
    "std_list = []\n",
    "estimator_list = []\n",
    "folds_list = []\n",
    "\n",
    "for k in [3, 5, 10, 15]:\n",
    "    for nearest_neighbor in range(2,25,2):   # tuning num of nearest neghbour classifiers \n",
    "        mean_acc, std_acc, estimator = train_test_knn_cv_remote.remote(X_train, Y_train, nearest_neighbor, k=k)\n",
    "        means_list.append(mean_acc)\n",
    "        std_list.append(std_acc)\n",
    "        estimator_list.append(estimator)\n",
    "        n_list.append(nearest_neighbor)\n",
    "        folds_list.append(k)\n",
    "\n",
    "mean_list = ray.get(means_list)\n",
    "std_list = ray.get(std_list)\n",
    "estimator_list = ray.get(estimator_list)\n",
    "\n",
    "optimal = np.column_stack((mean_list, std_list, n_list, folds_list,  estimator_list))\n",
    "optimal = pd.DataFrame(sorted(optimal, key=lambda x:x[0], reverse=True), columns=[\"Mean_Val_Acc\", \"Std_Val_Acc\", \"Num_nearest_neighbor\", \"Num_Folds\", \"Best_Estimator\"])\n",
    "\n",
    "# Display top 5 results along with params sorted on accuracy\n",
    "optimal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31561461794019935"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = optimal.loc[0,\"Best_Estimator\"].predict(X_test)\n",
    "accuracy(Y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_random_forest(X_train, Y_train, X_valid, Y_valid, num_classifiers=100, depth=5):\n",
    "    \"\"\"\n",
    "    Given training and validation data, return the classification accuracy of a random forest \n",
    "    model. Defaults use num_classifiers=100 and depth=5.\n",
    "    \"\"\"\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    clf = RandomForestClassifier(n_estimators=num_classifiers, max_depth=depth).fit(X_train, Y_train)\n",
    "    predictions = clf.predict(X_valid)\n",
    "    return accuracy_score(Y_valid, predictions)\n",
    "\n",
    "# using parallelization to speed up the training\n",
    "@ray.remote\n",
    "def train_test_random_forest_remote(X_train, Y_train, X_valid, Y_valid, num_classifiers=100, depth=5):\n",
    "    return train_test_random_forest(X_train, Y_train, X_valid, Y_valid, num_classifiers, depth)\n",
    "\n",
    "\n",
    "def train_test_random_forest_cv(X_train, Y_train, num_classifiers=100, depth=5, k=5):\n",
    "    from sklearn.model_selection import cross_validate\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    rand_forest = RandomForestClassifier(n_estimators=num_classifiers, max_depth=depth) # .fit(X_train, Y_train)\n",
    "    cv_results = cross_validate(rand_forest, X=X_train, y=Y_train, cv=k, return_train_score=False, return_estimator=True)\n",
    "    \n",
    "    max_ind = np.where(cv_results[\"test_score\"] == max(cv_results[\"test_score\"]))\n",
    "    max_estimator = cv_results[\"estimator\"][max_ind[0][0]]\n",
    "    return np.mean(cv_results[\"test_score\"]), np.std(cv_results[\"test_score\"]), max_estimator\n",
    "\n",
    "@ray.remote(num_return_vals=3)\n",
    "def train_test_random_forest_cv_remote(X_train, Y_train, num_classifiers=100, depth=5, k=5):\n",
    "    return train_test_random_forest_cv(X_train, Y_train, num_classifiers, depth, k)\n",
    "\n",
    "# ray.get(train_test_random_forest_cv_remote.remote(X_train, Y_train, num_classifiers=60, depth=10, k=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean_Val_Acc</th>\n",
       "      <th>Std_Val_Acc</th>\n",
       "      <th>Num_classifiers</th>\n",
       "      <th>Depth_per_classifier</th>\n",
       "      <th>Num_Folds</th>\n",
       "      <th>Best_Estimator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.362706</td>\n",
       "      <td>0.015601</td>\n",
       "      <td>450</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.358622</td>\n",
       "      <td>0.014503</td>\n",
       "      <td>350</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.358575</td>\n",
       "      <td>0.013926</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.351923</td>\n",
       "      <td>0.012889</td>\n",
       "      <td>400</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.326223</td>\n",
       "      <td>0.018270</td>\n",
       "      <td>500</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Mean_Val_Acc  Std_Val_Acc  Num_classifiers  Depth_per_classifier  \\\n",
       "0      0.362706     0.015601              450                     5   \n",
       "1      0.358622     0.014503              350                     5   \n",
       "2      0.358575     0.013926              500                     5   \n",
       "3      0.351923     0.012889              400                     5   \n",
       "4      0.326223     0.018270              500                     4   \n",
       "\n",
       "   Num_Folds                                     Best_Estimator  \n",
       "0          5  (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "1          5  (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "2          5  (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "3          5  (DecisionTreeClassifier(class_weight=None, cri...  \n",
       "4          5  (DecisionTreeClassifier(class_weight=None, cri...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_list = []\n",
    "d_list = []\n",
    "means_list = []\n",
    "std_list = []\n",
    "estimator_list = []\n",
    "folds_list = []\n",
    "\n",
    "for k in [5]:      # tuning number of folds , 3, 10, 15\n",
    "    for n in range(500, 349, -50):   # tuning the number of classifiers\n",
    "        for d in range(3, 6):      # tuning the depth of each classifier\n",
    "            mean_acc, std_acc, estimator  = train_test_random_forest_cv_remote.remote(X_train, Y_train, num_classifiers=n, depth=d, k=k)\n",
    "            means_list.append(mean_acc)\n",
    "            std_list.append(std_acc)\n",
    "            estimator_list.append(estimator)\n",
    "            n_list.append(n)\n",
    "            d_list.append(d)\n",
    "            folds_list.append(k)\n",
    "        \n",
    "mean_list = ray.get(means_list)\n",
    "std_list = ray.get(std_list)\n",
    "estimator_list = ray.get(estimator_list)\n",
    "\n",
    "optimal = np.column_stack((mean_list, std_list, n_list, d_list, folds_list, estimator_list))\n",
    "optimal = pd.DataFrame(sorted(optimal, key=lambda x:x[0], reverse=True), columns=[\"Mean_Val_Acc\", \"Std_Val_Acc\", \"Num_classifiers\", \"Depth_per_classifier\", \"Num_Folds\", \"Best_Estimator\"])\n",
    "\n",
    "# Display top 5 results along with params sorted on accuracy\n",
    "optimal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3588039867109635"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = optimal.loc[0,\"Best_Estimator\"].predict(X_test)\n",
    "accuracy(Y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_svm(X_train, Y_train, X_valid, Y_valid, C=10):\n",
    "    \"\"\"\n",
    "    Given training and validation data, return the classification accuracy of a support vector \n",
    "    machine model. Defaults use penalty param C=10 for training.\n",
    "    \"\"\"\n",
    "    from sklearn.svm import LinearSVC\n",
    "    clf = LinearSVC(C = 10).fit(X_train, Y_train)\n",
    "    predictions = clf.predict(X_valid)\n",
    "    return accuracy_score(Y_valid, predictions)\n",
    "\n",
    "# using parallelization to speed up the training\n",
    "@ray.remote\n",
    "def train_test_svm_remote(X_train, Y_train, X_valid, Y_valid, C=10):\n",
    "    return train_test_svm(X_train, Y_train, X_valid, Y_valid, C)\n",
    "\n",
    "def train_test_svm_cv(X_train, Y_train, C=10, k=5):\n",
    "    from sklearn.model_selection import cross_validate    \n",
    "    from sklearn.svm import LinearSVC\n",
    "    svm = LinearSVC(C = C)\n",
    "    cv_results = cross_validate(svm, X=X_train, y=Y_train, cv=k, return_train_score=False, return_estimator=True)\n",
    "    \n",
    "    max_ind = np.where(cv_results[\"test_score\"] == max(cv_results[\"test_score\"]))\n",
    "    max_estimator = cv_results[\"estimator\"][max_ind[0][0]]\n",
    "    return np.mean(cv_results[\"test_score\"]), np.std(cv_results[\"test_score\"]), max_estimator\n",
    "\n",
    "@ray.remote(num_return_vals=3)\n",
    "def train_test_svm_cv_remote(X_train, Y_train, C=10, k=5):\n",
    "    return train_test_svm_cv(X_train, Y_train, C, k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean_Val_Acc</th>\n",
       "      <th>Std_Val_Acc</th>\n",
       "      <th>Regularization_penalty</th>\n",
       "      <th>Num_Folds</th>\n",
       "      <th>Best_Estimator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.188200</td>\n",
       "      <td>0.038128</td>\n",
       "      <td>61</td>\n",
       "      <td>5</td>\n",
       "      <td>LinearSVC(C=61, class_weight=None, dual=True, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.184905</td>\n",
       "      <td>0.086496</td>\n",
       "      <td>56</td>\n",
       "      <td>5</td>\n",
       "      <td>LinearSVC(C=56, class_weight=None, dual=True, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.183687</td>\n",
       "      <td>0.089390</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>LinearSVC(C=31, class_weight=None, dual=True, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.169497</td>\n",
       "      <td>0.064307</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>LinearSVC(C=6, class_weight=None, dual=True, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.164938</td>\n",
       "      <td>0.067196</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>LinearSVC(C=11, class_weight=None, dual=True, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Mean_Val_Acc  Std_Val_Acc  Regularization_penalty  Num_Folds  \\\n",
       "0      0.188200     0.038128                      61          5   \n",
       "1      0.184905     0.086496                      56          5   \n",
       "2      0.183687     0.089390                      31          5   \n",
       "3      0.169497     0.064307                       6          5   \n",
       "4      0.164938     0.067196                      11          5   \n",
       "\n",
       "                                      Best_Estimator  \n",
       "0  LinearSVC(C=61, class_weight=None, dual=True, ...  \n",
       "1  LinearSVC(C=56, class_weight=None, dual=True, ...  \n",
       "2  LinearSVC(C=31, class_weight=None, dual=True, ...  \n",
       "3  LinearSVC(C=6, class_weight=None, dual=True, f...  \n",
       "4  LinearSVC(C=11, class_weight=None, dual=True, ...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penalty_list = []\n",
    "means_list = []\n",
    "std_list = []\n",
    "estimator_list = []\n",
    "folds_list = []\n",
    "\n",
    "for k in [5]:  # tuning number of folds 3, 5, 10, 15\n",
    "    for c in range(1,101,5):    # tuning penalty param c\n",
    "        mean_acc, std_acc, estimator = train_test_svm_cv_remote.remote(X_train, Y_train, C=c, k=k)\n",
    "        means_list.append(mean_acc)\n",
    "        std_list.append(std_acc)\n",
    "        estimator_list.append(estimator)\n",
    "        penalty_list.append(c)\n",
    "        folds_list.append(k)\n",
    "    \n",
    "mean_list = ray.get(means_list)\n",
    "std_list = ray.get(std_list)\n",
    "estimator_list = ray.get(estimator_list)\n",
    "\n",
    "optimal = np.column_stack((mean_list, std_list, penalty_list, folds_list, estimator_list))\n",
    "optimal = pd.DataFrame(sorted(optimal, key=lambda x:x[0], reverse=True), columns=[\"Mean_Val_Acc\", \"Std_Val_Acc\", \"Regularization_penalty\", \"Num_Folds\", \"Best_Estimator\"])\n",
    "\n",
    "# Display top 5 results along with params sorted on accuracy\n",
    "optimal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2425249169435216"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = optimal.loc[0,\"Best_Estimator\"].predict(X_test)\n",
    "accuracy(Y_test, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
